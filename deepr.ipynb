{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0307e9",
   "metadata": {},
   "source": [
    "# CS598 Deep Learning for Healthcare Final Project\n",
    "## Reproduction of Deepr: A Convolutional Net for Medical Records\n",
    "### Juan Alvarez Martinez, Shane Sepac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5c535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Include summary and report of findings here [200 words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0ba21",
   "metadata": {},
   "source": [
    "## Load MIMIC-III Dataset. \n",
    "Several csv files are needed from the MIMIC-III dataset: ADMISSIONS, PATIENTS, DIAGNOSES_ICD, and PROCEDURES_ICD. These files can be loaded automatically out of S3, or you can place them in `<project_root>/mimic3`. \n",
    "- If loading out of S3, ensure you have all environment variables from .env.sample copied and instantiated in a .env file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4700fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/homebrew/lib/python3.11/site-packages (1.26.109)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: pyhealth in /opt/homebrew/lib/python3.11/site-packages (1.1.3)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.109 in /opt/homebrew/lib/python3.11/site-packages (from boto3) (1.29.109)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/homebrew/lib/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/homebrew/lib/python3.11/site-packages (from pyhealth) (2.0.0)\n",
      "Requirement already satisfied: rdkit>=2022.03.4 in /opt/homebrew/lib/python3.11/site-packages (from pyhealth) (2022.9.5)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in /opt/homebrew/lib/python3.11/site-packages (from pyhealth) (1.2.2)\n",
      "Requirement already satisfied: networkx>=2.6.3 in /opt/homebrew/lib/python3.11/site-packages (from pyhealth) (3.1)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from pyhealth) (4.65.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/homebrew/lib/python3.11/site-packages (from botocore<1.30.0,>=1.29.109->boto3) (1.26.15)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: Pillow in /opt/homebrew/lib/python3.11/site-packages (from rdkit>=2022.03.4->pyhealth) (9.5.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn>=0.24.2->pyhealth) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn>=0.24.2->pyhealth) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn>=0.24.2->pyhealth) (3.1.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.8.0->pyhealth) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.8.0->pyhealth) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.8.0->pyhealth) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.8.0->pyhealth) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->pyhealth) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->torch>=1.8.0->pyhealth) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install the required dependencies\n",
    "%pip install boto3 python-dotenv pandas pyhealth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8383fc65",
   "metadata": {},
   "source": [
    "### Get MIMIC-3 Data\n",
    "Attempt to load MIMIC-3 data out of S3 if the relevant CSV files are not already in the mimic3 folder at the project root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9753cec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ADMISSIONS.csv...\n",
      "Found PATIENTS.csv...\n",
      "Found DIAGNOSES_ICD.csv...\n",
      "Found PROCEDURES_ICD.csv...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from utils import copy_file_from_s3\n",
    "\n",
    "data_folder = \"mimic3\"\n",
    "required_files = [\"ADMISSIONS.csv\", \"PATIENTS.csv\", \"DIAGNOSES_ICD.csv\", \"PROCEDURES_ICD.csv\"]\n",
    "\n",
    "for i, fn in enumerate(required_files):\n",
    "  if not os.path.exists(f\"{data_folder}/{fn}\"):\n",
    "    print(f\"Cannot find {fn} in {data_folder}, trying to download from S3...\")\n",
    "    copy_file_from_s3(fn, data_folder)\n",
    "  else:\n",
    "    print(f\"Found {fn}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f9202ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dataset.patients: patient_id -> <Patient>\n",
      "\n",
      "<Patient>\n",
      "    - visits: visit_id -> <Visit> \n",
      "    - other patient-level info\n",
      "    \n",
      "    <Visit>\n",
      "        - event_list_dict: table_name -> List[Event]\n",
      "        - other visit-level info\n",
      "    \n",
      "        <Event>\n",
      "            - code: str\n",
      "            - other event-level info\n",
      "\n",
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 46520\n",
      "\t- Number of visits: 58976\n",
      "\t- Number of visits per patient: 1.2678\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 4.0711\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 46520\\n\\t- Number of visits: 58976\\n\\t- Number of visits per patient: 1.2678\\n\\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\\n\\t- Number of events per visit in PROCEDURES_ICD: 4.0711\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyhealth.datasets import MIMIC3Dataset\n",
    "\n",
    "mimic3_ds = MIMIC3Dataset(\"./mimic3/\", [\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\"]) #pyhealth does not support mapping ICD-9 to ICD-10 codes.\n",
    "\n",
    "mimic3_ds.info()\n",
    "mimic3_ds.stat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df3a35f",
   "metadata": {},
   "source": [
    "## Sequencing EMR: Creating Sentences representing patient episodes\n",
    "Per Deepr, an EMR must be translated into a sentence for use downstream the model. An EMR is a sequence of time-stamped visit episodes. Each episode involves a series of diagnoses and treatments, called a phrase. Each phrase is separated by a time interval equal to `(0–1], (1–3], (3–6], (6–12], and 12+` or `TRANSFER`, with the latter indicating a transfer between care providers (separate departments within the same hospital or between hospitals.) Infrequent words are coded with `RAREWORD`, which indicates the word has appeared <100 times. Per the Deepr paper, an example sentence looks as follows:\n",
    "\n",
    "```\n",
    "1910 Z83 911 1008 D12 K31 1-3m R94 RAREWORD H53 Y83 M62 Y92 E87 T81 RAREWORD RAREWORD 1893 D12 S14 738 1910 1916 Z83 0-1m T91 RAREWORD Y83 Y92 K91 M10 E86 6-12m K31 1008 1910 Z13 Z83.\n",
    "```\n",
    "\n",
    "Note: In the sentence above, diagnoses are in ICD-10 format (a character followed by digits) and procedures are in digits. \n",
    "\n",
    "The MIMIC-3 dataset provides ICD-9 codes, and these will be used, but the level-3 variant of them for consistency with the original paper. It can also be noted that the encounter and discharge datetimes for visits are between the years 2100-2200 in order to deidentify patients, however, the time interval between visits is indeed preserved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852caebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Find rare words (diagnoses and procedures with counts of less than 100)\n",
    "'''\n",
    "word_cnts = {}\n",
    "for i, p in enumerate(mimic3_ds.patients.values()):\n",
    "  for _, v in p.visits.items():\n",
    "    words = []\n",
    "    for e in v.get_event_list('DIAGNOSES_ICD'):\n",
    "      words.append(e.code)\n",
    "\n",
    "    for e in v.get_event_list('PROCEDURES_ICD'):\n",
    "      words.append(e.code)\n",
    "  \n",
    "  for word in words:\n",
    "    # If the word is already in the dictionary, increment the count\n",
    "    if word in word_cnts:\n",
    "        word_cnts[word] += 1\n",
    "    # Otherwise, add the word to the dictionary with a count of 1\n",
    "    else:\n",
    "        word_cnts[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc89c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import timedelta_to_interval\n",
    "import random\n",
    "import json\n",
    "\n",
    "'''\n",
    "Translate EMRs into sentences outlined by the paper. A sentence consists of phrases, which are randomly shuffled diagnosis and procedure codes, separated by the \n",
    "time interval between visits, if the time interval exists. Sentences should have 100 words max.\n",
    "\n",
    "While looping over each patient:\n",
    "  1. Sort visits by encounter_time\n",
    "  2. Find the time interval between each visit and generate its relevant string word\n",
    "  3. Build arrays of diagnosis and procedure codes for each visit, replacing ICD-10 codes with less than 100 usages with RAREWORD\n",
    "  4. Randomly shuffle each array of diagnosis and procedure codes, then append the time interval string if available. This represents a phrase.\n",
    "    Concat each phrase to an array, which will be concatenated to form the final sentence. If the concatenation would form a sentence longer\n",
    "    than 100 words, min(100, words(sentence)) is adhered to.\n",
    "'''\n",
    "sentences = []\n",
    "for i, p in enumerate(mimic3_ds.patients.values()):\n",
    "\n",
    "  # Sort patient visits by encounter_time\n",
    "  sorted_visits = sorted(p.visits.items(), key=lambda v: v[1].encounter_time) # sort by encounter time in order to guage interval between visits\n",
    "\n",
    "  # Generate timestamps in between visits\n",
    "  timestamps = list(map(lambda visit: visit[1].encounter_time, sorted_visits))\n",
    "  time_intervals = [\n",
    "    t2 - t1\n",
    "    for t1, t2 in zip(timestamps[:-1], timestamps[1:])\n",
    "  ]\n",
    "  # Convert timestamps to month intervals as specified in paper\n",
    "  time_interval_strs = timedelta_to_interval(time_intervals)\n",
    "\n",
    "  # event_diagnoses_ls = (visit, diagnoses_codes)\n",
    "  event_diagnoses_ls = []\n",
    "  # event_procedures_ls = (visit, procedure_codes)\n",
    "  event_procedures_ls = []\n",
    "\n",
    "  # Helper function to create arrays with RAREWORD using list comprehension\n",
    "  def handle_event(event_list, word_cnts):\n",
    "      return [\"RAREWORD\" if e.code in word_cnts and word_cnts[e.code] < 100 else e.code for e in event_list]\n",
    "\n",
    "  # build arrays of diagnoses and procedures on a visit level, add to event_diagnoses_ls or event_procedures_ls\n",
    "  for _, v in sorted_visits:\n",
    "      visit_diagnoses = handle_event(v.get_event_list('DIAGNOSES_ICD'), word_cnts)\n",
    "      event_diagnoses_ls.append(visit_diagnoses)\n",
    "\n",
    "      visit_procedures = handle_event(v.get_event_list('PROCEDURES_ICD'), word_cnts)\n",
    "      event_procedures_ls.append(visit_procedures)\n",
    "\n",
    "\n",
    "  # Randomly shuffle diagnosis and procedure codes and append a time interval after, if available. Ensure the output sentence will not be more than 100 words.\n",
    "  arrs = []\n",
    "  word_cnt = 0\n",
    "  for i, vd in enumerate(event_diagnoses_ls):\n",
    "      arr = vd + event_procedures_ls[i]\n",
    "      random.shuffle(arr)\n",
    "      if i < len(time_interval_strs):\n",
    "          arr.append(time_interval_strs[i])\n",
    "\n",
    "      new_word_cnt = word_cnt + len(arr)\n",
    "\n",
    "      if new_word_cnt > 100:\n",
    "          # Calculate the number of elements needed to reach exactly 100 words\n",
    "          elements_needed = 100 - word_cnt\n",
    "          # Take a subset of arr to make new_word_cnt equal 100\n",
    "          arr = arr[:elements_needed]\n",
    "          arrs.append(arr)\n",
    "          break\n",
    "\n",
    "      arrs.append(arr)\n",
    "      word_cnt = new_word_cnt\n",
    "\n",
    "  # Combine all codes and time interval to create a phrase, representing a visit\n",
    "  phrases = [\" \".join(arr) for arr in arrs]\n",
    "  # Combine all phrases to create a sentence, representing a sequence as outlined by the paper\n",
    "  sentence = \" \".join(phrases)\n",
    "  sentences.append(sentence)\n",
    "\n",
    "# output to json file\n",
    "output_dir = \"data\"\n",
    "output_filename = \"sentences.json\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(output_dir, output_filename), \"w\") as json_file:\n",
    "  json.dump(sentences, json_file)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d6957a",
   "metadata": {},
   "source": [
    "### Test that output sentences satisfy the following conditions:\n",
    "- There is a sentence for each patient\n",
    "- Each sentence is capped to max 100 words\n",
    "- Multi visit patients have visits separated by a timestamp\n",
    "- Words should not exist in their ICD-10 form if used less than 100 times (should be replaced with RAREWORD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62b42736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# There should be one sentence per patient\n",
    "num_patients = len(mimic3_ds.patients)\n",
    "num_sentences = len(sentences)\n",
    "assert(num_patients == num_sentences)\n",
    "\n",
    "# There should be max 100 words per sentence\n",
    "word_lengths = map(lambda s: len(s.split()), sentences)\n",
    "assert(max(list(word_lengths)) <= 100)\n",
    "\n",
    "# There should be no word in any of the sentences that is present less than 100 times\n",
    "rarewords = [word for word, count in word_cnts.items() if count < 100]\n",
    "for sentence in sentences:\n",
    "  words_of_sentence = sentence.split()\n",
    "  rareword_violations = list(filter(lambda w: w in word_cnts and word_cnts[w] < 100, words_of_sentence))\n",
    "  assert(len(rareword_violations) == 0)\n",
    "\n",
    "\n",
    "# Patients with multiple visits should have timestamps separating their visits i.e. 1-3m or 12+m #TODO: Add TRANSFER to regex\n",
    "pattern = re.compile(r\"[-+]\")\n",
    "for i, p in enumerate(mimic3_ds.patients.values()):\n",
    "    if len(p.visits) > 1:\n",
    "        if not pattern.search(sentences[i]):\n",
    "            print(f\"Failed assertion for sentences[{i}]: '{sentences[i]}'\")\n",
    "            assert(False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
